1-[This slide highlights the comprehensive training on near-infrared spectroscopy (NIR) offered by Nagoya University, led by Tetsuya Inagaki, emphasizing collaboration with Kasetsart University (KU) and Naresuan University (NU).]
2-[The slide introduces a practical guide on near-infrared spectral analysis using Python and ChatGPT, emphasizing the transition from chemometrics to machine learning.]
3-[This slide outlines the application of machine learning and chemometrics to spectral analysis, emphasizing the importance of understanding correlation and causality in the analysis process.]
4-[The slide outlines the key topics covered in the presentation on near-infrared spectral analysis, including fundamentals of chemometrics, methods such as Lambert-Beer Law and Classical Least Squares, and preprocessing techniques for spectral data.]
5-[The slide outlines the table of contents for a presentation on machine learning fundamentals and practical spectral operations, covering topics such as clustering, k-Nearest Neighbors, decision tree algorithms, regression analysis, support vector machines, neural networks, spectral data loading, target variable distribution exploration, spectral visualization, peak detection, correlation spectra, baseline correction, curve fitting, and spectral heatmap visualization.]
6-[The slide outlines practical applications of chemometrics and machine learning in near-infrared spectral analysis, including outlier detection, standardization, PLS regression, cross-validation, model optimization, hyperspectral imaging data analysis, and the use of Convolutional Neural Networks (CNN) for analysis.]
7-[This slide outlines the application of machine learning and chemometrics to spectral analysis, emphasizing the importance of correlation, causality, and the No Free Lunch Theorem in the field.]
8-[The slide highlights the varying levels of understanding and reliance on hardware and software, emphasizing the importance of large language models (LLMs) in software development.]
9-[Key Point: Skills required for near-infrared spectral analysis in the future will involve acting as a mediator between software and hardware.]
10-[The key point of this slide is that when dealing with massive amounts of data, a calibration curve can be treated as a black box, but for limited data sets, understanding the underlying principles of the calibration curve is crucial for reliable use in spectral analysis using machine learning and chemometrics.]
11-[The slide emphasizes the importance of distinguishing between correlation and causation in data analysis, highlighting examples such as ambulance dispatches and deaths, global population and Earth's temperature, lycopene quantification in tomatoes, and deep-learning model training on YouTube videos to recognize cats.]
12-[The key point of this slide is that for small- to medium-sized datasets in near-infrared spectral analysis, the choice of algorithm is crucial, and access to large-scale datasets is important for achieving effective results.]
13-[The No Free Lunch Theorem states that there is no universally superior optimization strategy for all problems, emphasizing the importance of utilizing domain-specific knowledge in optimization rather than relying solely on general-purpose search algorithms.]
14-[The key point of this slide is that in near-infrared spectral analysis, both predictive accuracy and robustness must be ensured, as highlighted by the No Free Lunch Theorem.]
15-[This slide outlines the application of machine learning and chemometrics to spectral analysis, emphasizing the importance of correlation and causality in the analysis process.]
16-[The slide emphasizes the importance of setting up the Python (Jupyter Notebook) environment, highlighting its powerful, object-oriented nature, wide library availability, and ease of writing efficient code, specifically using Anaconda and Jupyter Notebook for an interactive computing environment in the course.]
17-[The key point of this slide is to guide researchers on how to set up the Python (Jupyter Notebook) environment by entering their email address on the website and following the link sent to download and install Jupyter Notebook.]
18-[This slide provides a step-by-step guide on setting up the Python (Jupyter Notebook) environment for near-infrared spectral analysis, including instructions on changing file names, running cells, writing programs, checking usage, and moving folders.]
19-[This slide provides instructions on setting up the Python (Jupyter Notebook) environment, including running a cell, inserting a new cell, writing code, and running a program.]
20-[This slide provides guidance on setting up the Python (Jupyter Notebook) environment for near-infrared spectral analysis, highlighting the shortcut for displaying the help menu (Ctrl+Shift+h).]
21-[All programs used in this session for near-infrared spectral analysis can be downloaded from the provided GitHub link and should be moved to the specified directory on your computer.]
22-[Setting up Jupyter Notebook and downloading/copying data with Me and Ma from GitHub can be completed within 10 minutes.]
23-[This slide outlines the application of machine learning and chemometrics to spectral analysis, emphasizing the importance of correlation, causality, and the No Free Lunch Theorem in the field.]
24-[The slide is referring to the importance of efficiently managing and analyzing spectral data in engineering applications.]
25-[Prompt Engineering LLMs have the capability to automatically generate code.]
26-[Prompt Engineering utilizes advanced data analysis by executing the program on a server and providing the results.]
27-[This slide emphasizes the importance of understanding programming, debugging errors, and improving analysis techniques in near-infrared spectral analysis, specifically focusing on principal component analysis (PCA) and the need for a solid understanding of programming and spectroscopy domains for effective questioning and analysis.]
28-[Generate a Python program using pandas and sklearn libraries to read an Excel file, perform mean-centering on spectral data, apply PCA, and create a scatter plot of PC1 and PC2 scores for Thai researchers studying near-infrared spectral analysis.]
29-[This slide presents various large language models (LLMs) like Prompt Engineering ChatGPT, Grok, Gemini, and Claude, emphasizing the importance of utilizing social media platforms for accessing up-to-date information, as textbooks alone may not suffice.]
30-[Installing GitHub Copilot in VS Code can accelerate programming, with instructions available in "SpeAna00_tips.ipynb," using Jupyter Notebook for clearer explanations.]
31-[A Python script named "pptx2txt.ipynb" was developed to extract text from PowerPoint slides, summarize the content in English using GPT (OpenAI), translate the summaries into Thai using Google Cloud Translation API, and save the results with slide numbers in a .txt file, which is also available on GitHub in the repository "word_extract_gpt_th."]
32-[This slide outlines the application of machine learning and chemometrics to spectral analysis, emphasizing the importance of understanding correlation and causality, as well as the No Free Lunch Theorem.]
33-[This slide introduces basic Python programming concepts relevant for near-infrared spectral analysis, including keyboard shortcuts, variables, lists, tuples, boolean types, if statements, for loops, and defining functions.]
34-[This slide explains the process of installing and importing libraries in Python for near-infrared spectral analysis, highlighting the structure of libraries composed of packages, modules, and functions.]
35-[Understanding instances, parameters, methods, and attributes in near-infrared spectral analysis allows for the effective utilization of any machine learning library, as the usage of these components remains consistent across different algorithms.]
36-[To install the required libraries for near-infrared spectral analysis using chemometrics, researchers should navigate to the directory containing the requirements.txt file in Anaconda Prompt and run "pip install -r requirements.txt" command.]
37-[The slide outlines the table of contents for a presentation on near-infrared spectral analysis, emphasizing the application of machine learning and chemometrics, as well as the importance of correlation and causality in the analysis process.]
38-[This slide discusses the process of importing Excel files for data analysis in the context of near-infrared spectral analysis.]
39-[This slide outlines the application of machine learning and chemometrics to spectral analysis, emphasizing the importance of correlation, causality, and the No Free Lunch Theorem.]
40-[This slide introduces various matrix operations, including solving simultaneous linear equations using inverse matrices, and encourages researchers to review these operations in Python using the provided notebook.]
41-[This slide discusses solving simultaneous linear equations using inverse matrices, emphasizing the matrix operation aspect of systems of equations.]
42-[The slide discusses using the least squares method with inverse matrices to determine coefficients a and b in a linear equation that minimizes the sum of squared errors for predicting acidity based on sugar content in near-infrared spectral analysis.]
43-[This slide discusses solving simultaneous linear equations using matrix representation to find coefficients a and b that minimize the least squares method through matrix operations and partial derivatives.]
44-[Understanding the distinctions between DataFrames in pandas and ndarrays in NumPy is crucial for near-infrared spectral analysis.]
45-[This slide outlines the table of contents for a presentation on the fundamentals of chemometrics, covering topics such as the Lambert-Beer Law, Classical Least Squares Method, Inverse Least Squares Method, Principal Component Analysis, Partial Least Squares Regression, and preprocessing of spectral data.]
46-[Near-infrared spectroscopy provides nondestructive and non-contact material characterization with moderate spatial resolution, offering molecular vibration information through overtones and combination bands of fundamental vibrations observed in the infrared region.]
47-[The slide highlights that near-infrared (NIR) spectroscopy in the mid-infrared region with low absorption allows for nondestructive measurements, while broad and overlapping absorptions in the NIR region present challenges in interpretation, necessitating the use of chemometrics.]
48-[Absorptions observed in the near-infrared region (800-2500nm) are primarily due to OH, NH, and CH groups in various substances such as coffee beans, sugar, carrot, human arm, wood, and polymer film.]
49-[Near-infrared spectroscopy provides nondestructive measurements within seconds, capturing complex spectral patterns of various components in cellulose, leading to the need for chemometrics analysis.]
50-[This slide explains the relationship between absorbance and light intensity in near-infrared spectral analysis, highlighting that absorbance is the logarithm of transmittance based on Lambert-Beer's law in a nickel sulfate aqueous solution.]
51-[This slide explains how Lambert-Beer's law can be used to predict the concentration of an unknown sample from its absorbance, with concentration on the x-axis and absorbance on the y-axis, where the slope represents Molar absorptivity × Path length.]
52-[The Classical Least Squares (CLS) method extends Lambert-Beer’s law to analyze multiple components and wavelengths for extracting useful information in near-infrared spectral analysis.]
53-[This slide highlights the application of chemometrics, specifically classical least squares (CLS), for extracting useful information from near-infrared spectral analysis by utilizing Lambert-Beer's law with two chemical species at two wavelengths to calculate absorbance.]
54-[This slide discusses the use of chemometrics, specifically classical least squares (CLS), for extracting useful information from near-infrared spectral analysis by considering two chemical species at two wavelengths based on Lambert-Beer's law.]
55-[This slide discusses the use of chemometrics, specifically classical least squares (CLS), for extracting useful information from near-infrared spectral analysis by utilizing two chemical species at two specific wavelengths based on Lambert-Beer's law.]
56-[Chemometrics using classical least squares (CLS) can effectively extract useful information from near-infrared spectral data by applying Lambert-Beer's law, even with multiple chemical species, wavelengths, and samples.]
57-[Chemometrics, specifically classical least square (CLS) analysis, involves measuring spectra and concentrations, establishing calibration curves, and predicting concentrations of unknown samples based on measured spectra.]
58-[The key point of this slide is that in chemometrics for near-infrared spectral analysis, classical least square (CLS) method involves multiplying by the inverse matrix of C from the left, but since C is typically a tall matrix, its inverse cannot be calculated.]
59-[The key point of this slide is that chemometrics, specifically classical least squares (CLS), aims to predict the composition of a chemical matrix (C) from known matrices (A) and (K) using training samples.]
60-[This slide demonstrates a classical least square (CLS) simulation using two normal distributions combined with added noise to predict matrix C from matrix A and determine matrix K from matrix A and known C for training and prediction purposes in near-infrared spectral analysis.]
61-[The slide discusses the use of classical least squares (CLS) in chemometrics for predicting concentrations and pure spectra simultaneously by training on known data matrices A and C to determine matrix K.]
62-[The slide discusses the use of classical least square (CLS) simulation in chemometrics for predicting matrix C from matrix A, but notes that CLS is not commonly used for this purpose.]
63-[The slide discusses the use of classical least square (CLS) in chemometrics for predicting matrix C from matrix A, highlighting the limitation of CLS when the number of components is incorrect and explaining why it is not commonly used.]
64-[When the number of components is incorrect in classical least square (CLS) chemometrics, both concentration and pure spectrum predictions are negatively affected.]
65-[The slide discusses the use of classical least squares (CLS) in chemometrics for predicting matrix C from matrix A, highlighting the challenges that arise when the number of components is incorrect.]
66-[Chemometrics, specifically classical least squares (CLS), can accurately estimate both pure spectra and concentrations when the correct number of components is used for predicting matrix C from matrix A.]
67-[The slide discusses how classical least squares (CLS) in chemometrics aims to predict matrix C from matrix A by attributing errors to Y-direction errors and performing least squares with concentration on the X-axis and absorbance on the Y-axis.]
68-[The key point of this slide is that accurate calibration in near-infrared spectral analysis using chemometrics relies on including all quantitative information in the concentration matrix to model the measured spectrum matrix effectively.]
69-[This slide demonstrates the successful application of near-infrared spectroscopy combined with chemometrics for rapid and accurate prediction of chemical properties in Thai herbal medicines.]
70-[Chemometrics techniques like CLS and ILS (inverse least square) are used to model the relationship between measured spectra and concentration matrices, with PILS representing the correlation between concentration and absorbance matrices.]
71-[Chemometrics techniques like CLS and ILS (inverse least square) allow for calibration in near-infrared spectral analysis, with ILS (similar to MLR) enabling calibration even without complete quantitative information.]
72-[Chemometrics techniques like CLS and ILS (including MLR) are used to predict matrix C from matrix A, but CLS may face computational challenges.]
73-[The key point of this slide is that chemometrics techniques like CLS and ILS (inverse least square), specifically ILS=MLR (Multiple linear regression), are used to predict matrix C from matrix A by determining matrix PILS or K, with the possibility of inverse matrix operations depending on the size of the matrices involved.]
74-[Chemometrics techniques like ILS (inverse least squares) and CLS are used to predict matrix C from matrix A by reducing the number of wavelength points to address collinearity issues.]
75-[Inverse least square (ILS) can achieve high prediction accuracy in near-infrared spectral analysis when using concentration information of only two components and appropriate wavelengths are selected, compared to the lower accuracy of classical least square (CLS) in such cases.]
76-[The slide discusses using ILS and PILS methods in chemometrics to find correlations between concentration and measured spectra matrices, highlighting the advantages and problems associated with these techniques and suggesting PCA as an efficient method to utilize all measured wavelength points.]
77-[Incorrectly assuming the presence of only two components in a three-component system can lead to failure in near-infrared spectral analysis using chemometrics.]
78-[This slide discusses the use of chemometrics in near-infrared spectral analysis, specifically focusing on combining spectra using various intensity ratios and different concentration levels with CLS and ILS methods.]
79-[This slide compares the Chemometrics techniques of Classical Least Squares (CLS) and Inverse Least Squares (ILS) for extracting useful information from near-infrared spectral analysis data.]
80-[This slide outlines the table of contents for a presentation on the fundamentals of chemometrics, covering topics such as Lambert-Beer Law, Classical Least Squares Method, Inverse Least Squares Method, Principal Component Analysis, Partial Least Squares Regression, and Preprocessing of Spectral Data.]
81-[Principal component analysis (PCA) in chemometrics involves decomposing the spectral matrix into loading and score matrices, similar to the decomposition in ILS (Independent Linear System), to extract useful information by representing the measured spectrum matrix with the largest factor first and subsequent independent factors.]
82-[Principal component analysis (PCA) in chemometrics allows for the visualization of data from new axes to extract useful information.]
83-[Principal Component Analysis (PCA) in chemometrics allows for the visualization of data along a new axis representing the direction of greatest variance, enabling the explanation of most data variance with just one axis instead of multiple variables like "height and weight."]
84-[Principal Component Analysis (PCA) in chemometrics helps extract useful information by viewing data from new axes representing the direction of greatest variance, with the second principal component capturing the variance unexplained by the first, although using both axes in data with two original axes eliminates the need for PCA.]
85-[Principal Component Analysis (PCA) in chemometrics involves viewing data from new axes, where the direction of the first principal component (PC) is represented by loading values and the values along the axis are known as scores, while the second PC similarly involves loading direction and score values.]
86-[Principal Component Analysis (PCA) in chemometrics involves treating near-infrared spectra as high-dimensional vectors to extract useful information, with the first principal component representing the most significant wavelength in a vector space context.]
87-[Principal component analysis (PCA) in chemometrics involves treating near-infrared spectra as vectors in a 100-dimensional space to extract useful information.]
88-[Principal component analysis (PCA) in chemometrics involves treating near-infrared spectra as vectors with absorbance values at different wavelength points, where each principal component (PC) represents a different orthogonal axis with zero correlation.]
89-[Principal Component Analysis (PCA) in chemometrics allows for understanding the direction of greatest variance in near-infrared spectral data by treating spectra as vectors with 100 absorbance values measured at 100 wavelength points.]
90-[Principal component analysis (PCA) in chemometrics involves treating near-infrared spectra as vectors, with the first principal component loading representing the mean spectrum, making it advantageous for quantitative analysis due to the change in axis direction between raw and mean-centered data.]
91-[Principal component analysis (PCA) in chemometrics involves decomposing the measured spectrum matrix into loading matrix 𝑃 and score matrix 𝑇, with any unexplained residual captured in the residual matrix R.]
92-[Principal component analysis (PCA) in near-infrared spectral analysis involves using a normalized orthogonal matrix P to extract useful information by multiplying the data matrix A by PT to obtain the scores matrix T, where the loadings determine the contribution of each component.]
93-[Principal Component Analysis (PCA) and Partial Least Squares Regression (PCR) are chemometric techniques used to extract useful information from near-infrared spectral data by expanding the measured spectrum matrix into loading and score matrices, enabling the calculation of the inverse matrix for regular TTT and performing multiple regression analysis to predict concentrations.]
94-[The key point of this slide is that in chemometrics for near-infrared spectral analysis, it is important to use uncorrelated explanatory variables to avoid instability in the analysis, with examples given using PCA and PCR techniques.]
95-[This slide introduces chemometrics techniques such as PCA and PCR to analyze near-infrared spectral data by explaining the concept of explained variance and demonstrating the application of PCA to data with mixed components.]
96-[The slide discusses chemometrics techniques such as PCA and PCR for near-infrared spectral analysis, highlighting the importance of explained variance in capturing spectral variation and emphasizing the benefits of using centered data for purer spectral information extraction.]
97-[This slide discusses chemometrics techniques such as PCA and PCR for near-infrared spectral analysis, emphasizing the importance of explained variance in extracting useful information from raw data.]
98-[This slide discusses the application of chemometrics, specifically PCA and PCR, in near-infrared spectral analysis, highlighting the importance of explained variance in extracting useful information from the data.]
99-[The slide demonstrates that the first three principal components in the PCA analysis explain over 99% of the spectral variance, indicating that these components are sufficient for capturing the key information, while the fourth principal component mainly represents noise and is deemed unnecessary.]
100-[The slide highlights the importance of explained variance in near-infrared spectral analysis, indicating that up to the third principal component covers over 99% of the spectral variance, making the fourth component unnecessary due to its low contribution rate and noise in the loadings.]
101-[Key indicators for evaluating the effectiveness of near-infrared spectral analysis (chemometrics) include the coefficient of determination (closer to 1 is better), root mean square error (smaller is better), and PRESS (Predicted Error Sum of Squares: smaller is better).]
102-[The slide emphasizes that the determination coefficient (R²) is not directly calculated as the square of the correlation coefficient, as demonstrated by examples where Excel and similar tools may provide different values due to the regression-based calculation method, highlighting the importance of understanding this distinction in chemometrics analysis.]
103-[This slide discusses the importance of dividing samples into calibration and validation data sets for creating accurate calibration curves in near-infrared spectral analysis, as well as the impact of measurement errors on the relationship between mass and force in Newtonian mechanics.]
104-[The slide discusses the importance of dividing samples into calibration and validation data sets for creating a calibration curve, determining the optimal number of factors, and assessing the validity of the model using error calculations on the validation data.]
105-[The slide emphasizes the importance of dividing samples into calibration and validation data to determine the optimal number of factors/components in chemometrics analysis for accurate predictions.]
106-[The key point of this slide is to emphasize the importance of validation in chemometrics for extracting useful information from near-infrared spectral analysis samples.]
107-[For a large number of samples, random division into calibration and validation sets is essential for chemometrics to accurately extract useful information through near-infrared spectral analysis.]
108-[This slide discusses the use of leave-one-out cross-validation in chemometrics for near-infrared spectral analysis to extract useful information from samples.]
109-[The slide discusses the use of leave-one-out cross-validation in chemometrics, where the initial sample is used for validation and the remaining samples for calibration to assess the model's performance.]
110-[The slide discusses the use of leave-one-out cross-validation in chemometrics, where each sample is sequentially left out as a validation set while performing calculations with the remaining samples.]
111-[Leave-one-out cross-validation in chemometrics involves iteratively using each sample once as validation to determine the optimal number of components by summing the validation errors.]
112-[In 5-fold cross-validation for near-infrared spectral analysis, samples are randomly arranged into five groups, with four groups used for calibration and one group for validation to store the validation error.]
113-[The key point of this slide is to demonstrate the process of N-hold cross-validation, specifically using a 5-fold cross-validation example where samples are arranged randomly and another group is used for validation after training on the remaining samples.]
114-[This slide demonstrates the use of 5-fold cross-validation in chemometrics, where samples are randomly arranged into 5 groups for validation to determine the optimal number of factors, a method commonly used in machine learning for hyperparameter tuning.]
115-[Chemometrics techniques such as N-hold cross validation and Partial Least-Squares methods are used to determine the optimal number of factors in near-infrared spectral analysis based on minimum PRESS, F-test, and eigenvalues.]
116-[Cross-validation is used in chemometrics to determine the optimal number of principal components, while accuracy evaluation is done separately using an evaluation dataset.]
117-[Principal Component Analysis (PCA) in chemometrics involves expanding the measured spectrum matrix into loading matrix 𝑃 and score matrix 𝑇 to decompose the data into loadings and scores based on spectral variance.]
118-[The slide explains the use of chemometrics, specifically Partial Least Squares (PLS), for analyzing near-infrared spectral data to extract useful information by calculating scores and loadings to maximize correlation between spectral and concentration matrices, with PLS2 offering a clearer concept by drawing new axes in both spectral and concentration spaces.]
119-[This slide illustrates chemometrics using PLS2 for extracting useful information by showing the relationship between spectral vectors and concentration vectors in near-infrared spectral analysis.]
120-[The key point of this slide is to explain that in chemometrics for near-infrared spectral analysis, the concentration vector is used to calculate the score on the axis, with the value of concentration 𝐴 being used as the initial score.]
121-[This slide discusses the use of Partial Least Squares 2 (PLS2) chemometrics for extracting useful information by calculating scores on an axis in the spectral space, which is similar to Concentration Least Squares (CLS) normalization.]
122-[This slide explains the process of using chemometrics, specifically PLS2, to extract valuable information from near-infrared spectral data by calculating scores on axes and obtaining values through normalization.]
123-[This slide discusses the use of Partial Least Squares 2 (PLS2) in near-infrared spectral analysis, emphasizing the calculation of scores along new axes for extracting valuable information.]
124-[This slide discusses the application of Partial Least Squares 2 (PLS2) chemometrics for extracting useful information from near-infrared spectral data by calculating scores on axes and normalizing concentration vectors, similar to Inverse Least Squares (ILS) and Classical Least Squares (CLS) methods.]
125-[This slide discusses using chemometrics, specifically Partial Least Squares (PLS) analysis, to extract useful information from near-infrared spectral data by calculating scores on axes and performing Concentration Least Squares (CLS) based on those scores to update the axis.]
126-[This slide discusses the application of chemometrics in near-infrared spectral analysis, emphasizing the process of extracting useful information through PLS2 spectral vector concentration vector normalization and repeating the score calculation on axis.]
127-[The key point of this slide is to highlight the iterative process of chemometrics using PLS2 spectral vectors and concentration vectors to extract useful information by calculating scores on axes and normalizing until the vector 𝑈 becomes constant.]
128-[The slide emphasizes the process of using chemometrics, specifically Partial Least Squares (PLS2), for extracting useful information from near-infrared spectral analysis by calculating scores on different axes and normalizing data to determine principal components sequentially.]
129-[The key point of this slide is that chemometrics, specifically Partial Least Squares 2 (PLS2), allows for independent modeling of errors in both the spectra and concentrations by expanding them into loading and score matrices and calculating their relationship.]
130-[This slide discusses the chemometric method of Partial Least Squares (PLS) for near-infrared spectral analysis, emphasizing the efficient calculation of scores on axes to maximize covariance between spectra and concentrations without the need for iterative calculations.]
131-[Chemometrics methods such as CLS, PCA, and PLS decompose spectral data into loadings and scores to maximize correlation with the response variable, spectral variance, and concentration, capturing unexplained variance in the residual matrix 𝑅R.]
132-[This slide discusses using chemometrics, specifically principal component analysis (PCA), to extract useful information from near-infrared spectra by combining three normal distributions with varying intensities and emphasizing the importance of explained variance, centering, and standardization, with a reference to a specific notebook for further details.]
133-[The slide discusses using chemometrics, specifically Partial Least Squares (PLS), to extract useful information by correlating intensities of N60 and N80 at 0.95, generating spectra with added noise, and estimating the intensities from the spectra using SpeAna07_2_PLS.ipynb.]
134-[The slide emphasizes the use of Partial Least Squares (PLS) chemometrics for extracting valuable information from near-infrared spectral analysis, directing researchers to refer to the SpeAna07_2_PLS.ipynb file for further details.]
135-[This slide outlines the key topics covered in the presentation on near-infrared spectral analysis, including fundamentals of chemometrics, methods such as Lambert-Beer Law and Classical Least Squares, and preprocessing techniques like Batch Import and Preprocessing Along Rows and Columns.]
136-[The key point of this slide is to encourage researchers to try batch importing spectral data using the SpeAna08_1-4_pretreatment.ipynb file.]
137-[Preprocessing between samples, such as centering and standardization, is essential for correcting differences at each wavelength and is commonly used in machine learning for near-infrared spectral analysis.]
138-[The slide introduces the preprocessing technique of centering and standardization using NumPy functions in the context of near-infrared spectral analysis, with a practical example provided in the SpeAna08_1-4_pretreatment.ipynb library.]
139-[This slide discusses the preprocessing techniques, such as centering, standardization, and Multiplicative Scatter Correction (MSC), used to correct for light scattering and optical path length variations in near-infrared spectral analysis.]
140-[Preprocessing in near-infrared spectral analysis can be applied across wavelengths due to the continuous nature of explanatory variables, unlike cases where units differ across samples.]
141-[The slide highlights the importance of preprocessing along the wavelength direction in near-infrared spectral analysis, emphasizing how negative peak positions in the second derivative correspond to original absorptions, allowing for accurate peak separation, maintenance of peak positions, and semi-quantitative evaluation of peak height changes, as well as the removal of scattering effects unrelated to the target chemical species through shift correction.]
142-[Preprocessing along the wavelength direction using second derivative analysis helps maintain accurate peak positions and allows for semi-quantitative evaluation of peak height changes, while correcting for scattering effects unrelated to the target chemical species.]
143-[Preprocessing along the wavelength direction, specifically applying second derivatives, can correct baselines, maintain peak positions accurately, and evaluate peak height changes semi-quantitatively in near-infrared spectral analysis.]
144-[Preprocessing in the wavelength direction, such as applying second derivative spectra, can be done between samples and across wavelengths.]
145-[Preprocessing techniques such as second derivative, quadratic polynomial approximation, and smoothing points can be applied in the wavelength direction to enhance near-infrared spectral analysis.]
146-[Preprocessing along the column direction in near-infrared spectral analysis involves applying second derivative, quadratic polynomial approximation, and smoothing points to the spectra to enhance data quality.]
147-[Preprocessing techniques such as second derivative, quadratic polynomial approximation, and smoothing points can be applied along the wavelength direction to enhance near-infrared spectral analysis.]
148-[Preprocessing in the wavelength direction, including second derivative using the Savitzky-Golay window, can be applied between samples and across wavelengths to enhance near-infrared spectral analysis.]
149-[Optimizing preprocessing methods such as second derivative smoothing with varying points can effectively reduce noise and eliminate small absorptions in near-infrared spectral analysis, with parameters like method, polynomial order, and smoothing points needing to be tailored to the specific wavelength characteristics and measurement conditions.]
150-[Preprocessing methods such as second derivative, Window Savitzky-Golay, Gap-segment, and Norris-gap can be applied along the wavelength direction for near-infrared spectral analysis.]
151-[Preprocessing methods such as SNV and MSC can be applied along the wavelength direction to remove light scattering effects in near-infrared spectral analysis.]
152-[Preprocessing techniques in near-infrared spectral analysis, such as SNV and MSC, can be applied along the wavelength direction to remove light scattering effects and calculate the mean spectrum.]
153-[Preprocessing techniques such as SNV, MSC, and baseline shift removal are applied along the wavelength direction to remove light scattering effects and correct spectral deviations based on the mean spectrum.]
154-[Preprocessing in the wavelength direction involves applying corrections such as SNV, MSC, and baseline shift removal to remove light scattering effects and standardize spectra using mean and standard deviation calculations for each individual spectrum.]
155-[The key point of this slide is that optimizing spectral measurement conditions is more important than relying on spectral preprocessing in order to obtain high-quality spectra with minimal interference from factors such as baseline shift, absorbance change, and noise.]
156-[The slide outlines the table of contents for a presentation on near-infrared spectral analysis, including chapters on machine learning fundamentals and practical spectral operations such as clustering, k-Nearest Neighbors, decision tree algorithms, regression analysis, support vector machines, neural networks, loading spectral data, exploring target variable distribution, spectral visualization, peak detection, correlation spectra, baseline correction, curve fitting, and spectral heatmap visualization.]
157-[This slide demonstrates the clustering of sepal width and length using near-infrared spectral analysis.]
158-[The slide introduces the Iris dataset created by Ronald Fisher in 1936, containing 50 samples from three species of iris flowers with four measured features each, and encourages trying it in the SpeAna09_1-6_machinelearning.ipynb file for clustering analysis.]
159-[The slide introduces the k-Nearest Neighbors (k-NN) method, which classifies or regresses unknown data points based on the k nearest known data points surrounding them, demonstrated in the SpeAna09_1-6_machinelearning.ipynb example.]
160-[Ensemble learning, specifically tree-based algorithms like Gradient Boosting and XGBoost, use multiple decision trees to improve classification or regression accuracy by aggregating predictions and preventing overfitting.]
161-[This slide introduces Support Vector Machine (SVM) as a method used in near-infrared spectral analysis (chemometrics).]
162-[Support Vector Machine (SVM) differs from the least squares method by utilizing a different loss function (evaluation function).]
163-[This slide revisits the least squares method, emphasizing the importance of understanding loss functions, before exploring other regression techniques like Ridge and Lasso Regression.]
164-[The slide discusses the concept of a loss function in near-infrared spectral analysis, emphasizing that the least squares method aims to minimize the sum of squared errors by finding values of a and b that reduce absolute error in variables like height and weight.]
165-[This slide discusses the concept of loss functions in near-infrared spectral analysis, emphasizing the minimization of errors in multiple linear regression models using methods such as Ordinary Least Squares (OLS), Least Absolute Deviations (LAD), Ridge Regression, and Lasso Regression.]
166-[The key point of this slide is to explain the concept of loss functions in near-infrared spectral analysis, emphasizing how the least squares method corresponds to a probability density function based on the normal distribution.]
167-[The slide discusses different regression methods in near-infrared spectral analysis, emphasizing the analytical solvability of the least squares method as a key advantage.]
168-[Support Vector Machine (SVM) is used to classify Hinoki (Japanese cypress) and Sugi (Japanese cedar) based on near-infrared spectral data, similar to Partial Least Squares Discriminant Analysis (PLS-DA), by setting a threshold for classification.]
169-[Support Vector Machine (SVM) effectively classifies Hinoki and Sugi based on spectral data, showing good separation but high loss values, indicating the need for regression to minimize errors in classification.]
170-[Support Vector Machine (SVM) Regression aims to minimize total loss using Hinge Loss, which is affected by outliers and differs from the ideal 0-1 Loss, making it a better choice than squared error for classification tasks.]
171-[Support Vector Machine (SVM) regression aims to minimize total loss using a hinge loss squared error function, where a loss value of 1 indicates incorrect predictions and 0 for correct predictions, although this ideal loss function can complicate the optimization process.]
172-[Support Vector Machine (SVM) regression minimizes total loss by using hinge loss as its loss function, where correct classification results in a loss of 0 and incorrect classification incurs greater loss the farther it is from the correct boundary.]
173-[Support Vector Machine (SVM) differs from least squares regression in the loss function used, with SVM offering high classification performance and supporting nonlinear classification through hinge loss.]
174-[Support Vector Machine (SVM) with the Inner Products Kernel Trick enables the simultaneous representation of multiple nonlinear feature mappings, allowing for the construction of highly complex decision boundaries.]
175-[Principal Component Analysis (PCA), Canonical Least Squares (CLS), Partial Least Squares (PLS), and Linear Regression (LB) are spectral decomposition methods, while Inverse Least Squares (ILS), Support Vector Machine (SVM), and Convolutional Neural Network (CNN) are regression analysis methods.]
176-[The slide outlines the table of contents for a presentation on near-infrared spectral analysis, covering machine learning fundamentals such as clustering, k-Nearest Neighbors, decision tree algorithms, regression analysis, support vector machines, and neural networks, as well as practical spectral operations including loading data, exploring target variable distribution, visualization, peak detection, correlation spectra, baseline correction, curve fitting, and heatmap visualization.]
177-[The slide discusses loading near-infrared spectral data of Agathis and Paulownia wood with different moisture levels, and provides guidance on transforming the data into various file formats for analysis using specific libraries.]
178-[This slide explains how to interpret boxplots, including the median, interquartile range (IQR), outliers, and whiskers, to understand the distribution of the target variable in near-infrared spectral analysis.]
179-[The slide introduces the practical application of spectral visualization using SpeAna10_1-9_practicaluse.ipynb in the context of near-infrared spectral analysis.]
180-[The slide suggests trying peak detection in the practical use of the SpeAna10_1-9 notebook for near-infrared spectral analysis.]
181-[The slide discusses the correlation spectrum, which shows the correlation coefficient between moisture content and spectral intensity at each wavelength, encouraging researchers to explore this in the practical use example provided in SpeAna10_1-9_practicaluse.ipynb.]
182-[Baseline correction and area intensity calculation are important steps in near-infrared spectral analysis, and researchers are encouraged to try this in the practical use example provided in the SpeAna10_1-9_practicaluse.ipynb file.]
183-[The slide introduces the use of the Voigt function for curve fitting in near-infrared spectral analysis, suggesting practical application in SpeAna10_1-9_practicaluse.ipynb.]
184-[The slide introduces the use of heatmaps for spectral visualization in near-infrared analysis, suggesting practical application in SpeAna10_1-9_practicaluse.ipynb.]
185-[The slide outlines practical applications of chemometrics and machine learning in near-infrared spectral analysis, covering topics such as outlier detection, PLS regression, model optimization, hyperspectral imaging data analysis, and the use of Convolutional Neural Networks (CNN) for analysis.]
186-[The key point of this slide is to introduce the use of Isolation Forest for outlier detection and removal in near-infrared spectral analysis, with a practical example provided in the SpeAna11_1-6_practicaluse.ipynb file.]
187-[PLS weight loadings aim to maximize the correlation between principal components and the target variable, while loadings reflect the correlation between principal components and spectral data.]
188-[Weight loadings in Partial Least Squares (PLS) indicate the contribution of each original variable to latent components for prediction, with regression coefficients scaled by the standard deviation of the target variable affecting prediction scale, and explained variance crucial for interpreting the significance of each component in the prediction model.]
189-[This slide emphasizes the importance of saving and loading the model using pickle in order to retain weight loadings and explained variance for near-infrared spectral analysis.]
190-[This slide highlights the efficiency of using GridSearchCV for cross-validation in near-infrared spectral analysis, with the recommendation to try it out in the provided practical use notebook, SpeAna11_1-6_practicaluse.ipynb.]
191-[The slide emphasizes the importance of utilizing an efficient pipeline for model optimization in near-infrared spectral analysis, encouraging researchers to try it in the provided practical use notebook SpeAna11_1-6_practicaluse.ipynb.]
192-[The slide outlines the practical application of chemometrics and machine learning in near-infrared spectral analysis, covering topics such as outlier detection, standardization, PLS regression, cross-validation, model optimization, hyperspectral imaging data analysis, and the use of convolutional neural networks for analysis.]
193-[This slide discusses the application of deep learning and machine learning techniques in image analysis for RGB and hyperspectral imaging in near-infrared spectral analysis (chemometrics).]
194-[The slide introduces the use of near-infrared spectral analysis for wood data, specifically referencing the SpeAna12_1_Imaging.ipynb file and the spectral.io.envi Library for analyzing NIR-HSI data.]
195-[The slide introduces the process of extracting images and spectra for near-infrared spectral analysis using the SpeAna12_1_Imaging.ipynb tool.]
196-[This slide discusses the identification of wood and background pixels in images using spectral information, with a practical example provided in the SpeAna12_1_Imaging.ipynb file.]
197-[This slide introduces the use of PLS regression spectral analysis and image analysis to visualize the spatial distribution of predicted target values, demonstrated in the SpeAna12_1_Imaging.ipynb file.]
198-[This slide introduces the use of PLS regression spectral analysis and image analysis to visualize the spatial distribution of predicted target values, demonstrated in the SpeAna12_1_Imaging.ipynb file.]
199-[This slide discusses the application of Convolutional Neural Networks (CNN) to predict moisture content using near-infrared images generated from hyperspectral imaging data.]
200-[This slide highlights the comprehensive training on near-infrared spectroscopy offered by Nagoya University, with contact information provided for Tetsuya Inagaki.]
